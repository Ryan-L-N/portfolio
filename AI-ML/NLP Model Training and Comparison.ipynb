{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4qn-V0gMT0p"
   },
   "source": [
    "## NLP and Model Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVmHQJeAMYG-"
   },
   "source": [
    "### Dataset Source:- https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4957,
     "status": "ok",
     "timestamp": 1742998748453,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "DvluzRUaFCw6",
    "outputId": "8fd98478-5bf8-4af4-c3f7-467be29df481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment  source\n",
      "0  So there is no way for me to plug it in here i...          0  amazon\n",
      "1                        Good case, Excellent value.          1  amazon\n",
      "2                             Great for the jawbone.          1  amazon\n",
      "3  Tied to charger for conversations lasting more...          0  amazon\n",
      "4                                  The mic is great.          1  amazon\n",
      "\n",
      "Dataset Info:\n",
      "Total reviews: 2748\n",
      "Reviews by source: {'amazon': 1000, 'yelp': 1000, 'imdb': 748}\n",
      "Sentiment distribution: {1: 1386, 0: 1362}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# URL to the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\"\n",
    "\n",
    "# Download the zip file\n",
    "response = requests.get(url)\n",
    "zip_file = ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Let's load and combine all three datasets\n",
    "amazon_data = pd.read_csv(\n",
    "    zip_file.open('sentiment labelled sentences/amazon_cells_labelled.txt'),\n",
    "    delimiter='\\t',\n",
    "    header=None,\n",
    "    names=[\"review\", \"sentiment\"]\n",
    ")\n",
    "\n",
    "imdb_data = pd.read_csv(\n",
    "    zip_file.open('sentiment labelled sentences/imdb_labelled.txt'),\n",
    "    delimiter='\\t',\n",
    "    header=None,\n",
    "    names=[\"review\", \"sentiment\"]\n",
    ")\n",
    "\n",
    "yelp_data = pd.read_csv(\n",
    "    zip_file.open('sentiment labelled sentences/yelp_labelled.txt'),\n",
    "    delimiter='\\t',\n",
    "    header=None,\n",
    "    names=[\"review\", \"sentiment\"]\n",
    ")\n",
    "\n",
    "# Add a source column to track where each review came from\n",
    "amazon_data['source'] = 'amazon'\n",
    "imdb_data['source'] = 'imdb'\n",
    "yelp_data['source'] = 'yelp'\n",
    "\n",
    "# Combine all datasets\n",
    "df = pd.concat([amazon_data, imdb_data, yelp_data], ignore_index=True)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Show dataset info\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"Total reviews: {len(df)}\")\n",
    "print(f\"Reviews by source: {df['source'].value_counts().to_dict()}\")\n",
    "print(f\"Sentiment distribution: {df['sentiment'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g1PRwUKE8B3"
   },
   "source": [
    "### Exercise 1: Basic Text Preprocessing with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhrWO6gAE_mv"
   },
   "source": [
    "#### Goal: Create a count vectorizer without using sklearn to understand how word frequencies work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1742400193774,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "DTVMAxXWE0uc",
    "outputId": "59ef92be-ae11-46ff-9ddc-568e0692e66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Frequency Matrix (first 5 rows):\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Vocabulary (first 10 words): ['00' '10' '100' '11' '12' '13' '15' '15g' '15pm' '17']\n",
      "Matrix shape: (2748, 5155)\n",
      "Number of documents: 2748\n",
      "Number of features (unique words): 5155\n",
      "Total elements: 14165940\n",
      "Non-zero elements: 30275\n",
      "Sparsity: 99.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 1: Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 2: Fit and transform the reviews into a term-frequency matrix\n",
    "tf_matrix = vectorizer.fit_transform(df[\"review\"])\n",
    "\n",
    "# Step 3: Convert the matrix to an array and print\n",
    "print(\"Term-Frequency Matrix (first 5 rows):\\n\", tf_matrix[:5].toarray())\n",
    "\n",
    "# Step 4: Print the feature names (vocabulary)\n",
    "print(\"Vocabulary (first 10 words):\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Step 5: Display the size of the matrix\n",
    "print(\"Matrix shape:\", tf_matrix.shape)\n",
    "print(f\"Number of documents: {tf_matrix.shape[0]}\")\n",
    "print(f\"Number of features (unique words): {tf_matrix.shape[1]}\")\n",
    "print(f\"Total elements: {tf_matrix.shape[0] * tf_matrix.shape[1]}\")\n",
    "print(f\"Non-zero elements: {tf_matrix.nnz}\")\n",
    "print(f\"Sparsity: {100.0 * (1 - tf_matrix.nnz / (tf_matrix.shape[0] * tf_matrix.shape[1])):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DQHN5WmFWS_"
   },
   "source": [
    "### Exercise 2: Train a Simple Classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSkJMRq6FXWv"
   },
   "source": [
    "#### Goal: Use TfidfVectorizer to convert text into features and train a simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1742400215043,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "tR17dTjxFBtS",
    "outputId": "e901a885-e619-4113-ebdf-c76c724ee92d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9934497816593887\n",
      "\n",
      "SVM Parameters:\n",
      "  - Kernel: rbf\n",
      "  - C (Regularization): 1.0\n",
      "  - Number of support vectors: [1214 1193]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Convert reviews to TF-IDF features\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "\n",
    "# Step 3: Use the sentiment column as labels\n",
    "y = df['sentiment']\n",
    "\n",
    "# Step 4: Initialize SVM classifier with RBF kernel\n",
    "# C=1.0 controls regularization (how strict the boundary is)\n",
    "# kernel='rbf' allows for non-linear decision boundaries\n",
    "model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "\n",
    "# Step 5: Train the SVM model\n",
    "model.fit(X,y)\n",
    "\n",
    "# Step 6: Predict on the same data (for demonstration)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Step 7: Evaluate accuracy\n",
    "accuracy = accuracy_score(y,predictions)\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "\n",
    "# Step 8: Display model parameters\n",
    "print(f\"\\nSVM Parameters:\")\n",
    "print(f\"  - Kernel: {model.kernel}\")\n",
    "print(f\"  - C (Regularization): {model.C}\")\n",
    "print(f\"  - Number of support vectors: {model.n_support_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWnY96AeHAX3"
   },
   "source": [
    "### Exercise 3: Train-Test Split and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFjRDTVsHBhI"
   },
   "source": [
    "#### Goal: Split data into training and testing sets, and evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742400236611,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "FbE-djNCFgWm",
    "outputId": "00a30922-bf2d-498e-a992-ebd93ecd2bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1923\n",
      "Testing samples: 825\n",
      "\n",
      "Test Accuracy: 0.8121\n",
      "Training Accuracy: 0.9943\n",
      "Difference (overfitting check): 0.1822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Split the data into training and testing sets (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Step 2: Train SVM on the training set\n",
    "model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Compare with training accuracy\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Difference (overfitting check): {train_accuracy - accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1znb3ZdJdJt"
   },
   "source": [
    "### Exercise 4: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZY0p4PCJd-1"
   },
   "source": [
    "#### Goal: Understand precision, recall, and F1-score using sklearn's evaluation tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1742400258748,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "ACzyqtNEHEE5",
    "outputId": "fd552d51-7884-48e0-81d1-fb92cd8a209e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[349  86]\n",
      " [ 69 321]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       435\n",
      "           1       0.79      0.82      0.81       390\n",
      "\n",
      "    accuracy                           0.81       825\n",
      "   macro avg       0.81      0.81      0.81       825\n",
      "weighted avg       0.81      0.81      0.81       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Step 2: Generate a classification report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKm6XPDBJvpt"
   },
   "source": [
    "### Exercise 5: Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM3stBSsJyAc"
   },
   "source": [
    "#### Goal: Use GridSearchCV to find the best hyperparameters for a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1742400400300,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "3B_afrUzJgGl",
    "outputId": "6bc57960-a1e8-4877-807e-22947eba69a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid to search:\n",
      "  C values: [0.1, 1.0, 10.0]\n",
      "  Gamma values: ['scale', 'auto']\n",
      "  Kernels: ['rbf', 'linear']\n",
      "  Total combinations: 12\n",
      "\n",
      "Searching for best parameters...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "==================================================\n",
      "GRID SEARCH RESULTS\n",
      "==================================================\n",
      "Best Parameters: {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best CV Score: 0.8315\n",
      "Test Accuracy with best params: 0.8145\n",
      "\n",
      "Top 3 parameter combinations:\n",
      "1. Params: {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "   CV Score: 0.8315\n",
      "2. Params: {'C': 1.0, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "   CV Score: 0.8304\n",
      "3. Params: {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "   CV Score: 0.8304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],           # Regularization strength\n",
    "    'gamma': ['scale', 'auto'],       # Kernel coefficient\n",
    "    'kernel': ['rbf', 'linear']       # Kernel type\n",
    "}\n",
    "\n",
    "print(\"Parameter grid to search:\")\n",
    "print(f\"  C values: {param_grid['C']}\")\n",
    "print(f\"  Gamma values: {param_grid['gamma']}\")\n",
    "print(f\"  Kernels: {param_grid['kernel']}\")\n",
    "print(f\"  Total combinations: {len(param_grid['C']) * len(param_grid['gamma']) * len(param_grid['kernel'])}\")\n",
    "\n",
    "# Step 2: Initialize GridSearchCV\n",
    "# cv=5 means 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42), \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Step 3: Fit the model (this will take 1-2 minutes)\n",
    "print(\"\\nSearching for best parameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Step 5: Evaluate on test set with best model\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy with best params: {test_accuracy:.4f}\")\n",
    "\n",
    "# Step 6: Show top 3 parameter combinations\n",
    "print(\"\\nTop 3 parameter combinations:\")\n",
    "results = grid_search.cv_results_\n",
    "indices = np.argsort(results['mean_test_score'])[::-1][:3]\n",
    "for i, idx in enumerate(indices, 1):\n",
    "    print(f\"{i}. Params: {results['params'][idx]}\")\n",
    "    print(f\"   CV Score: {results['mean_test_score'][idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrwkDBN2J8_z"
   },
   "source": [
    "### Exercise 6: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1742400402922,
     "user": {
      "displayName": "Jaineet Shah",
      "userId": "00614439216817576778"
     },
     "user_tz": 240
    },
    "id": "bI5sRQ7nJ1AP",
    "outputId": "5f35b18a-07c7-4dc4-a0b2-b4858e17b886"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Exercise 6: Train Random Forest Classifier\n",
    "# ========================================\n",
    "# Goal: Build and compare Random Forest with SVM\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Step 1 - Initialize Random Forest\n",
    "# Hint: Use RandomForestClassifier with these parameters:\n",
    "#   - n_estimators=100 (number of trees)\n",
    "#   - max_depth=None (let trees grow fully)\n",
    "#   - random_state=42 (for reproducibility)\n",
    "rf_model = ...  # YOUR CODE HERE\n",
    "\n",
    "# TODO: Step 2 - Train the Random Forest model\n",
    "# Hint: Use .fit() method with X_train and y_train\n",
    "...  # YOUR CODE HERE\n",
    "\n",
    "# TODO: Step 3 - Make predictions on test set\n",
    "# Hint: Use .predict() method on X_test\n",
    "rf_predictions = ...  # YOUR CODE HERE\n",
    "\n",
    "# TODO: Step 4 - Calculate accuracy\n",
    "# Hint: Use accuracy_score(y_test, rf_predictions)\n",
    "rf_accuracy = ...  # YOUR CODE HERE\n",
    "\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "# TODO: Step 5 - Compare with SVM\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"SVM Accuracy:          {test_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Winner: {'Random Forest' if rf_accuracy > test_accuracy else 'SVM'}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOH8VkMAsx2LJPDIm1dkSXv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recitationEnv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
